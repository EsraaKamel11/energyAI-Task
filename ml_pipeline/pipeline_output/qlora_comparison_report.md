
# Model Comparison Report

## Models Compared
- **Fine-tuned Model**: qlora_fine_tuned_ev_model
- **Baseline Model**: baseline_model
- **Benchmark**: benchmark

## Performance Metrics

### Standard Metrics

**ROUGE1**
- Fine-tuned: 0.0000
- Baseline: 0.0000
- Improvement: 0.0000 (+0.0%)
- Significant: No

**ROUGE2**
- Fine-tuned: 0.0000
- Baseline: 0.0000
- Improvement: 0.0000 (+0.0%)
- Significant: No

**ROUGEL**
- Fine-tuned: 0.0000
- Baseline: 0.0000
- Improvement: 0.0000 (+0.0%)
- Significant: No

**BLEU**
- Fine-tuned: 0.0000
- Baseline: 0.0000
- Improvement: 0.0000 (+0.0%)
- Significant: No

**EXACT_MATCH**
- Fine-tuned: 0.0000
- Baseline: 0.0000
- Improvement: 0.0000 (+0.0%)
- Significant: No

**SEMANTIC_SIMILARITY**
- Fine-tuned: 0.0000
- Baseline: 0.0000
- Improvement: 0.0000 (+0.0%)
- Significant: No

### Domain-Specific Metrics

**Price Accuracy**
- Fine-tuned: 0.0000
- Baseline: 0.0000
- Improvement: 0.0000 (+0.0%)
- Significant: No

**Technical Accuracy**
- Fine-tuned: 0.0000
- Baseline: 0.0000
- Improvement: 0.0000 (+0.0%)
- Significant: No

**Compatibility Accuracy**
- Fine-tuned: 0.0000
- Baseline: 0.0000
- Improvement: 0.0000 (+0.0%)
- Significant: No

## Performance Summary
- **Total Questions**: 2
- **Fine-tuned Latency**: 0.5821s
- **Baseline Latency**: 0.0767s
- **Latency Improvement**: -0.5055s
- **Fine-tuned Throughput**: 1.72 q/s
- **Baseline Throughput**: 13.04 q/s
- **Throughput Improvement**: -11.32 q/s

## Overall Assessment

- **Average Improvement**: 0.0000
- **Significant Improvements**: 0/9 metrics
- **Overall Performance**: Degraded
