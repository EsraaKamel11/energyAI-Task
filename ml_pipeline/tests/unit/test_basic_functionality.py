#!/usr/bin/env python3
"""
Basic functionality test for the ML pipeline
"""

import os
import sys
from pathlib import Path
import logging

# Add project root to path
sys.path.append(str(Path(__file__).parent))

def test_imports():
    """Test that all required modules can be imported"""
    print("Testing imports...")
    
    try:
        from config.settings import settings, logger
        print("âœ“ Config settings imported")
    except Exception as e:
        print(f"âœ— Config settings import failed: {e}")
        return False
    
    try:
        from src.data_collection import WebScraper, PDFExtractor
        print("âœ“ Data collection modules imported")
    except Exception as e:
        print(f"âœ— Data collection import failed: {e}")
        return False
    
    try:
        from src.data_processing import DataCleaner, QualityFilter, Normalizer, StorageManager
        print("âœ“ Data processing modules imported")
    except Exception as e:
        print(f"âœ— Data processing import failed: {e}")
        return False
    
    try:
        from src.training import load_model, LoRATrainer, TrainingLoop
        print("âœ“ Training modules imported")
    except Exception as e:
        print(f"âœ— Training import failed: {e}")
        return False
    
    try:
        from src.evaluation import BenchmarkCreator, MetricsCalculator
        print("âœ“ Evaluation modules imported")
    except Exception as e:
        print(f"âœ— Evaluation import failed: {e}")
        return False
    
    return True

def test_basic_functionality():
    """Test basic functionality without requiring external dependencies"""
    print("\nTesting basic functionality...")
    
    try:
        # Test data cleaner
        from src.data_processing import DataCleaner
        cleaner = DataCleaner()
        print("âœ“ DataCleaner initialized")
        
        # Test quality filter
        from src.data_processing import QualityFilter
        quality_filter = QualityFilter(min_length=10)
        print("âœ“ QualityFilter initialized")
        
        # Test normalizer
        from src.data_processing import Normalizer
        normalizer = Normalizer(model_name="gpt2")
        print("âœ“ Normalizer initialized")
        
        # Test storage manager
        from src.data_processing import StorageManager
        storage = StorageManager()
        print("âœ“ StorageManager initialized")
        
        return True
        
    except Exception as e:
        print(f"âœ— Basic functionality test failed: {e}")
        return False

def test_sample_data():
    """Test with sample data"""
    print("\nTesting with sample data...")
    
    try:
        import pandas as pd
        
        # Create sample data
        sample_texts = [
            "Electric vehicle charging stations are essential infrastructure.",
            "Level 2 charging uses 240-volt power and provides 10-60 miles per hour.",
            "DC fast charging can provide 60-80% charge in 20-30 minutes."
        ]
        
        sample_data = pd.DataFrame({
            "text": sample_texts,
            "source": ["sample"] * len(sample_texts),
            "timestamp": [pd.Timestamp.now()] * len(sample_texts)
        })
        
        print(f"âœ“ Created sample data with {len(sample_data)} records")
        
        # Test data cleaning
        from src.data_processing import DataCleaner
        cleaner = DataCleaner()
        cleaned_data = cleaner.process(sample_data, text_column="text")
        print(f"âœ“ Data cleaning completed, {len(cleaned_data)} records")
        
        # Test quality filtering
        from src.data_processing import QualityFilter
        quality_filter = QualityFilter(min_length=20)
        filtered_data = quality_filter.filter(cleaned_data, text_column="text")
        print(f"âœ“ Quality filtering completed, {len(filtered_data)} records")
        
        # Test normalization
        from src.data_processing import Normalizer
        normalizer = Normalizer(model_name="gpt2")
        normalized_data = normalizer.normalize(filtered_data, text_column="text")
        print(f"âœ“ Normalization completed")
        
        # Test storage
        from src.data_processing import StorageManager
        storage = StorageManager()
        storage.save_to_parquet(normalized_data, "test_output/sample_processed.parquet")
        print("âœ“ Data saved to parquet")
        
        return True
        
    except Exception as e:
        print(f"âœ— Sample data test failed: {e}")
        return False

def main():
    """Run all tests"""
    print("=== ML Pipeline Basic Functionality Test ===\n")
    
    # Create test output directory
    os.makedirs("test_output", exist_ok=True)
    
    # Run tests
    tests = [
        ("Import Test", test_imports),
        ("Basic Functionality Test", test_basic_functionality),
        ("Sample Data Test", test_sample_data)
    ]
    
    results = []
    for test_name, test_func in tests:
        print(f"\n--- {test_name} ---")
        try:
            result = test_func()
            results.append((test_name, result))
        except Exception as e:
            print(f"âœ— {test_name} failed with exception: {e}")
            results.append((test_name, False))
    
    # Summary
    print("\n=== Test Summary ===")
    passed = sum(1 for _, result in results if result)
    total = len(results)
    
    for test_name, result in results:
        status = "âœ“ PASS" if result else "âœ— FAIL"
        print(f"{test_name}: {status}")
    
    print(f"\nOverall: {passed}/{total} tests passed")
    
    if passed == total:
        print("ðŸŽ‰ All tests passed! The pipeline should work correctly.")
    else:
        print("âš  Some tests failed. Check the errors above.")
    
    return passed == total

if __name__ == "__main__":
    success = main()
    sys.exit(0 if success else 1) 
